[
  {
    "id": "FEAT-001",
    "title": "Multi-Language External Source Integration (Web/API)",
    "description": "Enable the agent to connect and retrieve diverse information (versions, docs, code examples, vulnerabilities) from sources for Go, C#, Python, TS, JS. Each client implementation will be version controlled.",
    "status": "todo",
    "subtasks": [
      {
        "id": "TASK-001.1",
        "title": "Define and Implement Generic API Client Interface",
        "description": "Create and commit the abstract base class or interface (`interfaces/api_client.py`) defining common methods (e.g., `search_repositories`, `get_latest_version`, `fetch_file_content`, `fetch_documentation`, `find_code_examples`, `check_vulnerabilities`) for all external API clients. Include basic docstrings.",
        "status": "completed",
        "deliverable": "Committed `interfaces/api_client.py`"
      },
      {
        "id": "TASK-001.2",
        "title": "Implement and Test Core GitHub API Client",
        "description": "Develop `clients/github_client.py` implementing the generic interface. Focus on repo search (code, issues, PRs), file content fetching, tag/commit checking, and potentially extracting code snippets from READMEs/Issues. Include comprehensive unit tests mocking API calls. Commit tested client.",
        "status": "completed",
        "deliverable": "Committed and tested `clients/github_client.py`"
      },
      {
        "id": "TASK-001.3",
        "title": "Implement and Test Package Manager Clients (PyPI, npm, Go, NuGet)",
        "description": "Develop/Enhance clients (`clients/pypi_client.py`, `clients/npm_client.py`, `clients/go_proxy_client.py`, `clients/nuget_client.py`) implementing the generic interface to query for package versions, dependencies, vulnerability info (if available), and links to documentation/repositories for Python, JS/TS, Go, and C#. Include comprehensive unit tests mocking API calls. Commit tested clients.",
        "status": "completed",
        "deliverable": "Committed and tested PyPI, npm, Go, NuGet clients"
      },
      {
        "id": "TASK-001.4",
        "title": "Develop Documentation Scraper/Parser",
        "description": "Implement a generic utility (`utils/doc_scraper.py`) capable of fetching and parsing content from common documentation site structures (e.g., ReadTheDocs, standard API reference formats) identified via package manager clients or GitHub repo links. Handle basic HTML cleaning. Commit tested scraper.",
        "status": "completed",
        "deliverable": "Committed and tested documentation scraper utility"
      },
      {
        "id": "TASK-001.5",
        "title": "Implement LLM-Powered Information Extraction Tool",
        "description": "Create a new agent tool (`tools/llm_info_extractor.py`) that takes raw content (docs, code files) retrieved by API clients/scrapers and uses targeted LLM prompts (`models/prompts/extraction_prompts.yaml`) to extract specific information like usage patterns, function signatures, setup instructions, or concise code examples. Include unit tests for prompt invocation. Commit tool and prompts.",
        "status": "completed",
        "deliverable": "Committed LLM info extractor tool and prompts"
      },
      {
        "id": "TASK-001.6",
        "title": "Implement Rate Limiting and Robust Error Handling",
        "description": "Enhance all implemented clients and scrapers with mechanisms to handle API rate limits gracefully (e.g., backoff strategies) and manage common HTTP/API/parsing errors. Update unit tests. Commit enhancements.",
        "status": "completed",
        "deliverable": "Committed clients/scrapers with rate limiting and error handling"
      },
      {
        "id": "TASK-001.7",
        "title": "Integrate Data Gathering Tools into Planner/Executor",
        "description": "Define new agent 'tools' wrapping the clients, scraper, and LLM extractor. Modify Planner (`app/agents/planner.py`) and Executor (`app/services/plan_executor.py`) to utilize these tools effectively for the 'deep search' goal. Implement integration tests covering multi-step data gathering. Commit integration.",
        "status": "completed",
        "deliverable": "Committed tools and planner/executor integration with tests"
      },
      {
        "id": "TASK-001.8",
        "title": "Update Configuration and Documentation for API Keys & Scrapers",
        "description": "Update `config.py` structure and `README.md` for API keys and any scraper-specific configurations (e.g., user-agent). Commit documentation and config changes.",
        "status": "completed",
        "deliverable": "Committed config structure and documentation updates"
      }
    ]
  },
  {
    "id": "FEAT-002",
    "title": "Multi-Language Version Control and Comparison Mechanisms",
    "description": "Implement capabilities to identify local dependencies (Go, C#, Python, TS, JS), compare them with external sources, and analyze code differences semantically.",
    "status": "completed",
    "subtasks": [
      {
        "id": "TASK-002.1",
        "title": "Implement and Test Multi-Language Dependency Parser",
        "description": "Create/Enhance `utils/dependency_parser.py` to accurately parse `requirements.txt`, `package.json`, `go.mod`, and `.csproj` (or relevant NuGet manifest files) to extract dependency names and version specifiers. Include unit tests covering all supported languages. Commit tested parser.",
        "status": "completed",
        "deliverable": "Committed and tested multi-language dependency parser"
      },
      {
        "id": "TASK-002.2",
        "title": "Implement and Test Multi-Language Version Comparison Service",
        "description": "Implement `services/version_comparer.py` using the multi-language parser (TASK-002.1) and relevant API clients (TASK-001.x) to compare local versions against latest external versions using semantic versioning. Include unit tests for all supported languages. Commit tested service.",
        "status": "completed",
        "deliverable": "Committed and tested version comparison service"
      },
      {
        "id": "TASK-002.3",
        "title": "Research and Select Advanced Code Diffing Technique",
        "description": "Investigate options for semantic code diffing (AST diffing, control-flow graph analysis, LLM-based). Document the chosen approach with rationale, considering multi-language compatibility. Commit research findings/decision document.",
        "status": "completed",
        "deliverable": "Committed document outlining chosen diffing strategy"
      },
      {
        "id": "TASK-002.4",
        "title": "Implement and Test Selected Code Diffing Technique",
        "description": "Implement the chosen code diffing technique in `services/code_differ.py`. Ensure it can handle syntax variations between supported languages where applicable. Include unit tests with examples from different languages. Commit tested differ.",
        "status": "completed",
        "deliverable": "Committed and tested multi-language code differ service"
      },
      {
        "id": "TASK-002.5",
        "title": "Implement and Test Git Context Integration",
        "description": "Create `utils/git_utils.py` to interact with the local Git repository (using `gitpython` or subprocess) to determine current branch, check for uncommitted changes, and potentially read file history. Include unit tests mocking Git commands/responses. Commit tested utility.",
        "status": "completed",
        "deliverable": "Committed and tested Git utility module"
      }
    ]
  },
  {
    "id": "FEAT-003",
    "title": "Proactive Analysis and Planning with Deep Search Context",
    "description": "Enable the agent to initiate analysis autonomously, leveraging the rich context gathered from external sources and LLM processing.",
    "status": "completed",
    "subtasks": [
      {
        "id": "TASK-003.1",
        "title": "Implement and Test Proactive Trigger Service",
        "description": "Design and implement `services/proactive_trigger.py` supporting scheduled intervals and file system change detection. Include unit tests for trigger logic. Commit tested service.",
        "status": "completed",
        "deliverable": "Committed and tested proactive trigger service"
      },
      {
        "id": "TASK-003.2",
        "title": "Develop and Test External Data Driven Analyzer",
        "description": "Develop `analysis/proactive_analyzer.py` that uses version comparison (TASK-002.2), vulnerability data (TASK-001.3), and potentially LLM-extracted best practices (TASK-001.5) to identify issues (outdated deps, vulns, deprecated patterns, deviations from current best practices). Define comprehensive issue structure. Include unit tests. Commit tested analyzer.",
        "status": "completed",
        "deliverable": "Committed and tested proactive analyzer module"
      },
      {
        "id": "TASK-003.3",
        "title": "Enhance Planner/Reflection for Proactive Task Generation",
        "description": "Adapt Planner (`app/agents/planner.py`) and Reflection Engine (`agent/reflection.py`) to evaluate issues from the analyzer (TASK-003.2), considering severity and project context, and generate sophisticated, multi-step plans (e.g., 'Update library X, find current usage examples via deep search, refactor local code based on examples, validate'). Implement integration tests. Commit enhancements.",
        "status": "completed",
        "deliverable": "Committed planner/reflection engine enhancements with tests"
      },
      {
        "id": "TASK-003.4",
        "title": "Develop and Test LLM Prompts for Proactive Solution Generation",
        "description": "Craft and test specific LLM prompts via `models/llm.py` to generate potential code fixes or refactoring suggestions based on proactive findings and retrieved external context (code examples, docs). Commit tested prompt templates.",
        "status": "completed",
        "deliverable": "Committed and tested proactive LLM solution prompts"
      }
    ]
  },
  {
    "id": "FEAT-004",
    "title": "Risk Management, LLM Validation, and Mitigation Strategies",
    "description": "Implement mechanisms to assess risks, use LLM for validation, handle incompatibilities, ensure safe application of changes, and allow for user control across supported languages.",
    "status": "completed",
    "subtasks": [
      {
        "id": "TASK-004.1",
        "title": "Develop and Test Risk Assessment Module",
        "description": "Create `analysis/risk_assessor.py` using LLM analysis (evaluating semantic diff TASK-002.4), dependency graph info, version jump size, and test results (TASK-004.4) to assign risk scores/levels to proposed changes across languages. Include unit tests. Commit tested module.",
        "status": "completed",
        "deliverable": "Committed and tested risk assessment module"
      },
      {
        "id": "TASK-004.2",
        "title": "Implement and Test Dependency Conflict Detection",
        "description": "Enhance dependency analysis (TASK-002.1) to explicitly detect potential conflicts across the supported languages. Implement logic in `analysis/conflict_detector.py`. Include unit tests. Commit tested detector.",
        "status": "completed",
        "deliverable": "Committed and tested conflict detector"
      },
      {
        "id": "TASK-004.3",
        "title": "Develop Basic Interactive Conflict Resolver (CLI)",
        "description": "Implement a basic CLI prompt mechanism (`ui/conflict_resolver.py`) presenting detected conflicts (TASK-004.2) to the user and suggesting potential resolutions. Commit resolver UI.",
        "status": "completed",
        "deliverable": "Committed CLI conflict resolver"
      },
      {
        "id": "TASK-004.4",
        "title": "Implement Enhanced Validation Service (Static Analysis, Tests)",
        "description": "Create/Enhance `services/validation_service.py` to optionally run configured static analysis tools (linters, security scanners relevant to Go, C#, Py, JS/TS) and execute language-specific test suites (`go test`, `dotnet test`, `pytest`, `npm test`) against proposed changes. Include unit/integration tests. Commit enhanced service.",
        "status": "completed",
        "deliverable": "Committed enhanced validation service with tests"
      },
      {
        "id": "TASK-004.5",
        "title": "Implement LLM-Based Code Validation/Testing Tool",
        "description": "Create a new agent tool (`tools/llm_code_tester.py`) that uses LLM prompts (`models/prompts/validation_prompts.yaml`) to evaluate generated/modified code snippets or external examples for correctness, adherence to best practices, or potential issues based on provided context (e.g., 'Does this Go code snippet correctly handle errors?', 'Is this C# implementation thread-safe?'). Commit tool and prompts.",
        "status": "completed",
        "deliverable": "Committed LLM code tester tool and prompts"
      },
      {
        "id": "TASK-004.6",
        "title": "Implement and Test Git-Based Rollback Mechanism",
        "description": "Implement a strategy in the Plan Executor using `utils/git_utils.py` (TASK-002.5): Create a temporary branch, apply changes, run validation (TASK-004.4 and potentially TASK-004.5). If valid, merge; otherwise, reset/delete the branch. Ensure atomicity. Include integration tests. Commit tested mechanism.",
        "status": "completed",
        "deliverable": "Committed and tested Git-based rollback mechanism"
      },
      {
        "id": "TASK-004.7",
        "title": "Implement and Test Configurable User Confirmation",
        "description": "Add settings to `config.py` for risk thresholds. Modify Plan Executor to check assessed risk (TASK-004.1) and trigger user confirmation (via UI module) if required before applying high-risk changes. Include unit tests. Commit tested feature.",
        "status": "completed",
        "deliverable": "Committed user confirmation feature with tests"
      }
    ]
  }
] 