import logging
from typing import TYPE_CHECKING, Any, Dict, List

# Use TYPE_CHECKING to avoid circular import issues
if TYPE_CHECKING:
    from .code_agent import CodeAgent
    from .sandbox_runner import SandboxExecutionResult

logger = logging.getLogger(__name__)

class PlanExecutor:
    """Executes the steps defined in a plan generated by the Planner."""

    def __init__(self, agent: 'CodeAgent'):
        """Initializes the PlanExecutor.

        Args:
            agent: The CodeAgent instance containing necessary components
                   (providers, managers, config, etc.).
        """
        self.agent = agent

    async def execute_plan(
        self,
        plan: List[Dict[str, Any]],
        execution_context: Dict[str, Any],
        response_data: Dict[str, Any]
    ) -> None:
        """Executes the plan steps sequentially, updating context and response data.

        Args:
            plan: The list of steps generated by the Planner.
            execution_context: Dictionary holding the intermediate state and results
                               (e.g., snippets, analysis).
            response_data: The main response dictionary to be returned to the user,
                           which will be updated with results and status.
        """
        logger.info(f"Starting plan execution with {len(plan)} steps.")
        query = execution_context["query"] # Get query from context

        for step_index, step in enumerate(plan):
            step_name = step.get("step")
            logger.info(f"Executing step {step_index + 1}/{len(plan)}: {step_name}")

            try:
                # --- Moved Step Execution Logic --- #
                if step_name == "Search Code (Vector Store)":
                    search_query_param = step.get('query', query)
                    use_keywords = step.get('use_keywords', True)
                    final_search_query = f"{search_query_param} {' '.join(execution_context['extracted_keywords'])}" if use_keywords else search_query_param
                    logger.info(f"Performing vector search with query: '{final_search_query}'")
                    # Use self.agent to access components
                    execution_context["code_snippets"] = await self.agent.vector_store_manager.search_code(final_search_query)
                    response_data["results"]["code_snippets"] = execution_context["code_snippets"]
                    logger.info(f"Found {len(execution_context['code_snippets'])} snippets from vector store.")
                    if not execution_context["code_snippets"]:
                            logger.warning("No relevant code snippets found in vector store.")
                            
                elif step_name == "Web Search":
                    web_query = step.get('query', query)
                    logger.info(f"Performing web search with query: '{web_query}'")
                    try:
                        if hasattr(self.agent, 'web_search'):
                                search_result = await self.agent.web_search(web_query)
                                execution_context["web_search_results"] = search_result
                                logger.info(f"Web search completed. Found {len(search_result)} results.")
                        else:
                                logger.warning("Web search tool call mechanism not implemented. Skipping actual search.")
                                execution_context["web_search_results"] = [{"title": "Tool Call Skipped", "snippet": "Web search tool call mechanism not implemented."}]
                                
                    except Exception as tool_e:
                            logger.error(f"Error during web search tool call: {tool_e}", exc_info=True)
                            execution_context["web_search_results"] = [{"title": "Error", "snippet": f"Web search failed: {tool_e}"}]
                            
                    response_data["results"]["web_search_results"] = execution_context["web_search_results"]

                elif step_name == "Search GitHub":
                    github_query = step.get('query', query)
                    language = step.get('language')
                    logger.info(f"Performing GitHub search with query: '{github_query}' (Lang: {language or 'any'})")
                    if self.agent.github_search_provider:
                        try:
                            search_result = await self.agent.github_search_provider.search(github_query, language=language)
                            execution_context["github_results"] = search_result
                            response_data["results"]["github_search_results"] = search_result
                            logger.info(f"GitHub search completed. Found {len(search_result)} results.")
                        except Exception as gh_e:
                            logger.error(f"Error during GitHub search: {gh_e}", exc_info=True)
                            execution_context["github_results"] = [{"error": f"GitHub search failed: {gh_e}"}]
                            response_data["results"]["github_search_results"] = execution_context["github_results"]
                    else:
                        logger.warning("GitHub search provider not available. Skipping step.")
                        execution_context["github_results"] = [{"error": "GitHub search provider not initialized."}]
                        response_data["results"]["github_search_results"] = execution_context["github_results"]

                elif step_name == "Search Stack Overflow":
                    so_query = step.get('query', query)
                    language = step.get('language')
                    logger.info(f"Performing Stack Overflow search with query: '{so_query}' (Lang/Tag: {language or 'any'})")
                    if self.agent.stackoverflow_search_provider:
                        try:
                            search_result = await self.agent.stackoverflow_search_provider.search(so_query, language=language)
                            execution_context["stackoverflow_results"] = search_result
                            response_data["results"]["stackoverflow_search_results"] = search_result
                            logger.info(f"Stack Overflow search completed. Found {len(search_result)} results.")
                        except Exception as so_e:
                            logger.error(f"Error during Stack Overflow search: {so_e}", exc_info=True)
                            execution_context["stackoverflow_results"] = [{"error": f"Stack Overflow search failed: {so_e}"}]
                            response_data["results"]["stackoverflow_search_results"] = execution_context["stackoverflow_results"]
                    else:
                        logger.warning("Stack Overflow search provider not available. Skipping step.")
                        execution_context["stackoverflow_results"] = [{"error": "Stack Overflow search provider not initialized."}]
                        response_data["results"]["stackoverflow_search_results"] = execution_context["stackoverflow_results"]

                elif step_name == "Analyze Code":
                    if not execution_context["code_snippets"] and not execution_context.get("web_search_results") and not execution_context.get("github_results") and not execution_context.get("stackoverflow_results"):
                        logger.warning("Skipping Analyze Code step: No code snippets or search results available.")
                        execution_context["analysis"] = "Analysis skipped: No code snippets or search results found."
                    else:
                        analysis_input_parts = []
                        if execution_context["code_snippets"]:
                            combined_code = "\n\n---\n\n".join([
                                f"File: {snippet['file_path']}\n```\n{snippet['code']}\n```"
                                for snippet in execution_context["code_snippets"] if snippet.get('code')
                            ])
                            if combined_code.strip():
                                analysis_input_parts.append("--- Local Code Snippets ---\n" + combined_code)
                        
                        if execution_context.get("web_search_results"):
                            web_info = "\n\n--- Web Search Results ---\n"
                            for res in execution_context["web_search_results"]:
                                web_info += f"Title: {res.get('title', 'N/A')}\nSnippet: {res.get('snippet', 'N/A')}\nURL: {res.get('url', 'N/A')}\n\n"
                            analysis_input_parts.append(web_info)
                            logger.info("Including web search results in analysis context.")

                        if execution_context.get("github_results"):
                            gh_info = "\n\n--- GitHub Search Results ---\n"
                            for res in execution_context["github_results"][:3]: # Limit results shown
                                gh_info += f"Repo: {res.get('repository', {}).get('full_name', 'N/A')}\nFile: {res.get('path', 'N/A')}\nURL: {res.get('html_url', 'N/A')}\n\n"
                            analysis_input_parts.append(gh_info)
                            logger.info("Including GitHub search results in analysis context.")
                            
                        if execution_context.get("stackoverflow_results"):
                            so_info = "\n\n--- Stack Overflow Search Results ---\n"
                            for res in execution_context["stackoverflow_results"][:3]: # Limit results shown
                                so_info += f"Title: {res.get('title', 'N/A')}\nURL: {res.get('link', 'N/A')}\nAnswered: {res.get('is_answered', False)}\n\n"
                            analysis_input_parts.append(so_info)
                            logger.info("Including Stack Overflow search results in analysis context.")

                        # Add Decomposed Queries to Context
                        if execution_context.get("decomposed_queries"):
                            unique_sub_queries = list(set(execution_context["decomposed_queries"]))
                            if len(unique_sub_queries) > 1 or (len(unique_sub_queries) == 1 and unique_sub_queries[0] != execution_context["query"]):
                                    decomp_info = "\n\n--- Original Query Decomposition ---"
                                    for i, sub_query in enumerate(execution_context["decomposed_queries"]):
                                            decomp_info += f"\n{i+1}. {sub_query}"
                                    analysis_input_parts.append(decomp_info)
                                    logger.info("Including decomposed queries in analysis context.")

                        if not analysis_input_parts:
                            execution_context["analysis"] = "Could not perform analysis: No valid content found in snippets or search results."
                            logger.warning(execution_context["analysis"])
                        else:
                            final_analysis_context = "\n".join(analysis_input_parts)
                            # Call analyze_code method on the agent instance
                            execution_context["analysis"] = await self.agent.analyze_code(
                                    code=final_analysis_context, 
                                    original_query=execution_context["query"]
                            )
                            logger.info("Code analysis completed.")
                    response_data["results"]["analysis_summary"] = execution_context["analysis"]

                elif step_name == "Generate Fix (JSON Output)":
                    if not execution_context["code_snippets"] and not execution_context.get("analysis"):
                            logger.warning("Skipping Generate Fix step: No code snippets or analysis available.")
                            # Use agent's method to generate standard error
                            code_fix = self.agent._generate_error_response("Fix generation skipped: No code or analysis input.")
                    else:
                        # Call _generate_code_fix method on the agent instance
                        code_fix = await self.agent._generate_code_fix(
                            execution_context["query"],
                            execution_context["code_snippets"],
                            execution_context["analysis"] or "No prior analysis available."
                        )
                        logger.info("Code fix generation process completed.")
                        
                    response_data["results"]["fix_details"] = code_fix
                    response_data["status"] = code_fix.get("status", "success") # Update status based on fix result
                    response_data["message"] = code_fix.get("explanation", "Workflow completed.") # Update message

                elif step_name == "Apply Fix":
                    logger.info("Attempting to apply generated fix...")
                    fix_details = response_data["results"].get("fix_details")
                    
                    if not fix_details or fix_details.get('status') == 'error':
                        logger.warning("Skipping Apply Fix: No valid fix details available.")
                        response_data["results"]["apply_fix_status"] = {"status": "skipped", "reason": "No valid fix details"}
                        continue

                    target_file = fix_details.get('file_path')
                    fixed_code = fix_details.get('fixed_code')
                    changes = fix_details.get('changes') # List of specific changes

                    if not target_file:
                        logger.warning("Skipping Apply Fix: Target file path not specified in fix details.")
                        response_data["results"]["apply_fix_status"] = {"status": "skipped", "reason": "Target file not specified"}
                        continue
                        
                    if not fixed_code and not changes:
                            logger.warning("Skipping Apply Fix: Neither 'fixed_code' nor 'changes' provided in fix details.")
                            response_data["results"]["apply_fix_status"] = {"status": "skipped", "reason": "No code/changes provided"}
                            continue
                            
                    # --- Actual edit_file Tool Call (Placeholder/Simulation) --- #
                    # TODO: Replace with actual tool call mechanism if available
                    edit_applied = False
                    edit_error = None
                    
                    if fixed_code:
                            code_edit_content = fixed_code
                            edit_instruction = f"Apply the generated code fix to {target_file}."
                            
                            try:
                                # Simulate success for now
                                edit_result = {"status": "simulated_success", "message": f"Simulated edit applied to {target_file}"}
                                logger.info(f"Simulated edit_file tool call successful for {target_file}. Result: {edit_result}")
                                edit_applied = True 
                                response_data["results"]["apply_fix_status"] = {"status": "success", "file": target_file, "message": edit_result.get("message")}
                                
                            except Exception as edit_e:
                                logger.error(f"Error calling edit_file tool for {target_file}: {edit_e}", exc_info=True)
                                edit_error = str(edit_e)
                                response_data["results"]["apply_fix_status"] = {"status": "error", "file": target_file, "error": edit_error}
                                
                    elif changes:
                        logger.warning(f"Apply Fix with 'changes' array not yet implemented. Skipping edit for {target_file}.")
                        response_data["results"]["apply_fix_status"] = {"status": "skipped", "file": target_file, "reason": "'changes' based edit not implemented"}

                elif step_name == "Validate Code (Sandbox)":
                    logger.info("Attempting to validate generated code in sandbox...")
                    fix_details = response_data["results"].get("fix_details")
                    code_to_validate = None

                    if fix_details and fix_details.get('status') != 'error':
                        code_to_validate = fix_details.get('fixed_code')
                    
                    # Use self.agent.sandbox_runner
                    if code_to_validate and self.agent.sandbox_runner:
                        try:
                            logger.info("Running code validation using DockerSandboxRunner.")
                            validation_result: 'SandboxExecutionResult' = await self.agent.sandbox_runner.run_code(
                                code_to_run=code_to_validate,
                                # timeout_seconds=self.agent.config.sandbox_timeout # Optional: Add timeout config
                            )
                            response_data["results"]["validation_status"] = validation_result.to_dict()
                            logger.info(f"Sandbox validation completed. Success: {validation_result.success}")
                        except Exception as sandbox_e:
                            logger.error(f"Error during sandbox execution: {sandbox_e}", exc_info=True)
                            response_data["results"]["validation_status"] = {
                                "status": "error",
                                "reason": f"Sandbox execution failed: {sandbox_e}",
                                "success": False
                            }
                    elif not self.agent.sandbox_runner:
                            logger.warning("Skipping Validate Code (Sandbox): Sandbox runner not available.")
                            response_data["results"]["validation_status"] = {"status": "skipped", "reason": "Sandbox runner not available"}
                    else: # No code to validate
                        logger.warning("Skipping Validate Code (Sandbox): No valid code found.")
                        response_data["results"]["validation_status"] = {"status": "skipped", "reason": "No code to validate"}

                elif step_name in ["Assess Clarity", "Extract Keywords", "Decompose Query"]:
                    # These steps are handled before plan execution
                    logger.debug(f"Skipping step '{step_name}' as it was handled in reflection phase.")
                    pass
                
                else:
                        logger.warning(f"Unknown plan step encountered: {step_name}")
                # --- End Moved Step Execution Logic --- #

            except Exception as step_e:
                logger.error(f"Error executing plan step '{step_name}': {step_e}", exc_info=True)
                response_data["status"] = "error"
                response_data["message"] = f"Error during step '{step_name}': {step_e}"
                # Stop further execution on error
                break
        else:
            # This block runs if the loop completes without a 'break'
            logger.info("Plan execution completed.") # Adjusted log message
            # Set default success status if not already set to error/warning
            if response_data.get("status") not in ["error", "warning", "clarification_needed"]:
                 response_data["status"] = "success"
                 response_data["message"] = response_data.get("message", "Plan execution completed successfully.")

            # Consolidate results population after loop (optional refinement)
            response_data["results"]["analysis_summary"] = execution_context.get("analysis", "Analysis step not reached or failed.")
            # Ensure fix_details exists, default to error if needed
            if "fix_details" not in response_data["results"]:
                 response_data["results"]["fix_details"] = self.agent._generate_error_response("Fix generation step not reached or failed.")

    # Optional helper methods can be defined here if needed
    # async def _execute_step(self, step, context, response): ...

    # Optional: Define helper methods for each step type
    # async def _execute_search_code_step(self, step, context, response):
    #     pass
    # async def _execute_analyze_code_step(self, step, context, response):
    #     pass
    # ... etc. 