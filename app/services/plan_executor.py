import logging
import os
import shutil
from typing import TYPE_CHECKING, Any, Dict, List

# Use TYPE_CHECKING to avoid circular import issues
if TYPE_CHECKING:
    from .code_agent import CodeAgent
    from .sandbox_runner import SandboxExecutionResult

logger = logging.getLogger(__name__)

class PlanExecutor:
    """Executes the steps defined in a plan generated by the Planner."""

    def __init__(self, agent: 'CodeAgent'):
        """Initializes the PlanExecutor.

        Args:
            agent: The CodeAgent instance containing necessary components
                   (providers, managers, config, etc.).
        """
        self.agent = agent

    async def execute_plan(
        self,
        plan: List[Dict[str, Any]],
        execution_context: Dict[str, Any],
        response_data: Dict[str, Any]
    ) -> None:
        """Executes the plan steps sequentially, updating context and response data.

        Args:
            plan: The list of steps generated by the Planner.
            execution_context: Dictionary holding the intermediate state and results
                               (e.g., snippets, analysis).
            response_data: The main response dictionary to be returned to the user,
                           which will be updated with results and status.
        """
        logger.info(f"Starting plan execution with {len(plan)} steps.")
        query = execution_context["query"] # Get query from context

        for step_index, step in enumerate(plan):
            step_name = step.get("step")
            logger.info(f"Executing step {step_index + 1}/{len(plan)}: {step_name}")

            try:
                # --- Moved Step Execution Logic --- #
                if step_name == "Search Code (Vector Store)":
                    search_query_param = step.get('query', query)
                    use_keywords = step.get('use_keywords', True)
                    final_search_query = f"{search_query_param} {' '.join(execution_context['extracted_keywords'])}" if use_keywords else search_query_param
                    logger.info(f"Performing vector search with query: '{final_search_query}'")
                    # --- ENHANCE-008: Add filter to main search step --- #
                    code_filter = {"type": "code_master"} # Default to searching master code
                    # Optionally allow plan to override filter, e.g. step.get('filter', default_filter)
                    execution_context["code_snippets"] = await self.agent.vector_store_manager.search_code(
                        final_search_query,
                        filter_dict=code_filter
                    )
                    # --- End ENHANCE-008 --- #
                    response_data["results"]["code_snippets"] = execution_context["code_snippets"]
                    logger.info(f"Found {len(execution_context['code_snippets'])} snippets from vector store matching filter: {code_filter}")
                    if not execution_context["code_snippets"]:
                            logger.warning("No relevant code snippets found in vector store.")
                            
                elif step_name == "Web Search":
                    web_query = step.get('query', query)
                    max_results = step.get('max_results', 5) # Allow plan to specify max results
                    logger.info(f"Performing web search with query: '{web_query}'")
                    
                    if self.agent.web_search_provider and self.agent.web_search_provider.client:
                        try:
                            search_result = await self.agent.web_search_provider.search(
                                web_query,
                                max_results=max_results
                            )
                            execution_context["web_search_results"] = search_result
                            logger.info(f"Web search completed via {self.agent.web_search_provider.__class__.__name__}. Found {len(search_result)} results.")
                        except Exception as tool_e:
                            logger.error(f"Error during web search via {self.agent.web_search_provider.__class__.__name__}: {tool_e}", exc_info=True)
                            execution_context["web_search_results"] = [{"title": "Error", "content": f"Web search failed: {tool_e}"}]
                    else:
                        logger.warning("Web search provider not available or not initialized. Skipping web search step.")
                        execution_context["web_search_results"] = [{"title": "Skipped", "content": "Web search provider not configured or failed to initialize."}]
                            
                    response_data["results"]["web_search_results"] = execution_context["web_search_results"]

                elif step_name == "Search GitHub":
                    github_query = step.get('query', query)
                    language = step.get('language')
                    logger.info(f"Performing GitHub search with query: '{github_query}' (Lang: {language or 'any'})")
                    if self.agent.github_search_provider:
                        try:
                            search_result = await self.agent.github_search_provider.search(github_query, language=language)
                            execution_context["github_results"] = search_result
                            response_data["results"]["github_search_results"] = search_result
                            logger.info(f"GitHub search completed. Found {len(search_result)} results.")
                        except Exception as gh_e:
                            logger.error(f"Error during GitHub search: {gh_e}", exc_info=True)
                            execution_context["github_results"] = [{"error": f"GitHub search failed: {gh_e}"}]
                            response_data["results"]["github_search_results"] = execution_context["github_results"]
                    else:
                        logger.warning("GitHub search provider not available. Skipping step.")
                        execution_context["github_results"] = [{"error": "GitHub search provider not initialized."}]
                        response_data["results"]["github_search_results"] = execution_context["github_results"]

                elif step_name == "Search Stack Overflow":
                    so_query = step.get('query', query)
                    language = step.get('language')
                    logger.info(f"Performing Stack Overflow search with query: '{so_query}' (Lang/Tag: {language or 'any'})")
                    if self.agent.stackoverflow_search_provider:
                        try:
                            search_result = await self.agent.stackoverflow_search_provider.search(so_query, language=language)
                            execution_context["stackoverflow_results"] = search_result
                            response_data["results"]["stackoverflow_search_results"] = search_result
                            logger.info(f"Stack Overflow search completed. Found {len(search_result)} results.")
                        except Exception as so_e:
                            logger.error(f"Error during Stack Overflow search: {so_e}", exc_info=True)
                            execution_context["stackoverflow_results"] = [{"error": f"Stack Overflow search failed: {so_e}"}]
                            response_data["results"]["stackoverflow_search_results"] = execution_context["stackoverflow_results"]
                    else:
                        logger.warning("Stack Overflow search provider not available. Skipping step.")
                        execution_context["stackoverflow_results"] = [{"error": "Stack Overflow search provider not initialized."}]
                        response_data["results"]["stackoverflow_search_results"] = execution_context["stackoverflow_results"]

                elif step_name == "Analyze Code":
                    if not execution_context["code_snippets"] and not execution_context.get("web_search_results") and not execution_context.get("github_results") and not execution_context.get("stackoverflow_results"):
                        logger.warning("Skipping Analyze Code step: No code snippets or search results available.")
                        execution_context["analysis"] = "Analysis skipped: No code snippets or search results found."
                    else:
                        analysis_input_parts = []
                        if execution_context["code_snippets"]:
                            combined_code = "\n\n---\n\n".join([
                                f"File: {snippet['file_path']}\n```\n{snippet['code']}\n```"
                                for snippet in execution_context["code_snippets"] if snippet.get('code')
                            ])
                            if combined_code.strip():
                                analysis_input_parts.append("--- Local Code Snippets ---\n" + combined_code)
                        
                        if execution_context.get("web_search_results"):
                            web_info = "\n\n--- Web Search Results ---\n"
                            for res in execution_context["web_search_results"]:
                                web_info += f"Title: {res.get('title', 'N/A')}\nSnippet: {res.get('snippet', 'N/A')}\nURL: {res.get('url', 'N/A')}\n\n"
                            analysis_input_parts.append(web_info)
                            logger.info("Including web search results in analysis context.")

                        if execution_context.get("github_results"):
                            gh_info = "\n\n--- GitHub Search Results ---\n"
                            for res in execution_context["github_results"][:3]: # Limit results shown
                                gh_info += f"Repo: {res.get('repository', {}).get('full_name', 'N/A')}\nFile: {res.get('path', 'N/A')}\nURL: {res.get('html_url', 'N/A')}\n\n"
                            analysis_input_parts.append(gh_info)
                            logger.info("Including GitHub search results in analysis context.")
                            
                        if execution_context.get("stackoverflow_results"):
                            so_info = "\n\n--- Stack Overflow Search Results ---\n"
                            for res in execution_context["stackoverflow_results"][:3]: # Limit results shown
                                so_info += f"Title: {res.get('title', 'N/A')}\nURL: {res.get('link', 'N/A')}\nAnswered: {res.get('is_answered', False)}\n\n"
                            analysis_input_parts.append(so_info)
                            logger.info("Including Stack Overflow search results in analysis context.")

                        # Add Decomposed Queries to Context
                        if execution_context.get("decomposed_queries"):
                            unique_sub_queries = list(set(execution_context["decomposed_queries"]))
                            if len(unique_sub_queries) > 1 or (len(unique_sub_queries) == 1 and unique_sub_queries[0] != execution_context["query"]):
                                    decomp_info = "\n\n--- Original Query Decomposition ---"
                                    for i, sub_query in enumerate(execution_context["decomposed_queries"]):
                                            decomp_info += f"\n{i+1}. {sub_query}"
                                    analysis_input_parts.append(decomp_info)
                                    logger.info("Including decomposed queries in analysis context.")

                        if not analysis_input_parts:
                            execution_context["analysis"] = "Could not perform analysis: No valid content found in snippets or search results."
                            logger.warning(execution_context["analysis"])
                        else:
                            final_analysis_context = "\n".join(analysis_input_parts)
                            # Call analyze_code method on the agent instance
                            execution_context["analysis"] = await self.agent.analyze_code(
                                    code=final_analysis_context, 
                                    original_query=execution_context["query"]
                            )
                            logger.info("Code analysis completed.")
                    response_data["results"]["analysis_summary"] = execution_context["analysis"]

                elif step_name == "Generate Fix (JSON Output)":
                    if not execution_context["code_snippets"] and not execution_context.get("analysis"):
                            logger.warning("Skipping Generate Fix step: No code snippets or analysis available.")
                            # Use agent's method to generate standard error
                            code_fix = self.agent._generate_error_response("Fix generation skipped: No code or analysis input.")
                    else:
                        # Call _generate_code_fix method on the agent instance
                        code_fix = await self.agent._generate_code_fix(
                            execution_context["query"],
                            execution_context["code_snippets"],
                            execution_context["analysis"] or "No prior analysis available."
                        )
                        logger.info("Code fix generation process completed.")
                        
                    response_data["results"]["fix_details"] = code_fix
                    response_data["status"] = code_fix.get("status", "success") # Update status based on fix result
                    response_data["message"] = code_fix.get("explanation", "Workflow completed.") # Update message

                elif step_name == "Apply Fix":
                    logger.info("Attempting to apply generated fix...")
                    fix_details = response_data["results"].get("fix_details")
                    apply_fix_status = {}
                    
                    if not fix_details or fix_details.get('status') == 'error':
                        logger.warning("Skipping Apply Fix: No valid fix details available.")
                        apply_fix_status = {"status": "skipped", "reason": "No valid fix details"}
                    else:
                        target_file = fix_details.get('file_path')
                        fixed_code = fix_details.get('fixed_code')

                        if not target_file:
                            logger.warning("Skipping Apply Fix: Target file path not specified in fix details.")
                            apply_fix_status = {"status": "skipped", "reason": "Target file not specified"}
                        elif not fixed_code:
                            # We are prioritizing fixed_code for now, ignoring changes array implementation
                            logger.warning("Skipping Apply Fix: 'fixed_code' not provided in fix details.")
                            apply_fix_status = {"status": "skipped", "reason": "No fixed_code provided"}
                        else:
                            # Basic path safety check: prevent absolute paths or attempts to go outside current dir structure
                            # This is NOT foolproof security, but a basic safeguard.
                            if os.path.isabs(target_file) or ".." in target_file:
                                logger.error(f"Security Risk: Apply fix blocked for potentially unsafe path: {target_file}")
                                apply_fix_status = {"status": "error", "file": target_file, "error": "Attempted to write to potentially unsafe path."}
                            else:
                                backup_file = f"{target_file}.bak"
                                try:
                                    # Create backup
                                    if os.path.exists(target_file):
                                        shutil.copy2(target_file, backup_file)
                                        logger.info(f"Created backup of {target_file} at {backup_file}")
                                    else:
                                        logger.warning(f"Target file {target_file} does not exist. Applying fix will create it.")
                                        backup_file = None # No backup created if file didn't exist
                                        
                                    # Ensure directory exists
                                    target_dir = os.path.dirname(target_file)
                                    if target_dir and not os.path.exists(target_dir):
                                        os.makedirs(target_dir)
                                        logger.info(f"Created directory {target_dir}")

                                    # Write the fixed code
                                    with open(target_file, 'w', encoding='utf-8') as f:
                                        f.write(fixed_code)
                                    
                                    logger.info(f"Successfully applied fix to {target_file}")
                                    apply_fix_status = {
                                        "status": "success", 
                                        "file": target_file, 
                                        "backup_created": backup_file
                                    }

                                except IOError as io_err:
                                    logger.error(f"IOError applying fix to {target_file}: {io_err}", exc_info=True)
                                    apply_fix_status = {"status": "error", "file": target_file, "error": f"File write error: {io_err}"}
                                except OSError as os_err:
                                    logger.error(f"OSError applying fix to {target_file} (e.g., backup failed): {os_err}", exc_info=True)
                                    apply_fix_status = {"status": "error", "file": target_file, "error": f"OS error during apply fix: {os_err}"}
                                except Exception as e:
                                    logger.error(f"Unexpected error applying fix to {target_file}: {e}", exc_info=True)
                                    apply_fix_status = {"status": "error", "file": target_file, "error": f"Unexpected error: {e}"}

                    response_data["results"]["apply_fix_status"] = apply_fix_status

                elif step_name == "Validate Code (Sandbox)":
                    logger.info("Attempting to validate generated code in sandbox...")
                    fix_details = response_data["results"].get("fix_details")
                    code_to_validate = None

                    if fix_details and fix_details.get('status') != 'error':
                        code_to_validate = fix_details.get('fixed_code')
                    
                    # Use self.agent.sandbox_runner
                    if code_to_validate and self.agent.sandbox_runner:
                        try:
                            logger.info("Running code validation using DockerSandboxRunner.")
                            validation_result: 'SandboxExecutionResult' = await self.agent.sandbox_runner.run_code(
                                code_to_run=code_to_validate,
                                # timeout_seconds=self.agent.config.sandbox_timeout # Optional: Add timeout config
                            )
                            response_data["results"]["validation_status"] = validation_result.to_dict()
                            logger.info(f"Sandbox validation completed. Success: {validation_result.success}")
                        except Exception as sandbox_e:
                            logger.error(f"Error during sandbox execution: {sandbox_e}", exc_info=True)
                            response_data["results"]["validation_status"] = {
                                "status": "error",
                                "reason": f"Sandbox execution failed: {sandbox_e}",
                                "success": False
                            }
                    elif not self.agent.sandbox_runner:
                            logger.warning("Skipping Validate Code (Sandbox): Sandbox runner not available.")
                            response_data["results"]["validation_status"] = {"status": "skipped", "reason": "Sandbox runner not available"}
                    else: # No code to validate
                        logger.warning("Skipping Validate Code (Sandbox): No valid code found.")
                        response_data["results"]["validation_status"] = {"status": "skipped", "reason": "No code to validate"}

                elif step_name in ["Assess Clarity", "Extract Keywords", "Decompose Query"]:
                    # These steps are handled before plan execution
                    logger.debug(f"Skipping step '{step_name}' as it was handled in reflection phase.")
                    pass
                
                else:
                        logger.warning(f"Unknown plan step encountered: {step_name}")
                # --- End Moved Step Execution Logic --- #

            except Exception as step_e:
                logger.error(f"Error executing plan step '{step_name}': {step_e}", exc_info=True)
                response_data["status"] = "error"
                response_data["message"] = f"Error during step '{step_name}': {step_e}"
                # Stop further execution on error
                break
        else:
            # This block runs if the loop completes without a 'break'
            logger.info("Plan execution completed.") # Adjusted log message
            # Set default success status if not already set to error/warning
            if response_data.get("status") not in ["error", "warning", "clarification_needed"]:
                 response_data["status"] = "success"
                 response_data["message"] = response_data.get("message", "Plan execution completed successfully.")

            # Consolidate results population after loop (optional refinement)
            response_data["results"]["analysis_summary"] = execution_context.get("analysis", "Analysis step not reached or failed.")
            # Ensure fix_details exists, default to error if needed
            if "fix_details" not in response_data["results"]:
                 response_data["results"]["fix_details"] = self.agent._generate_error_response("Fix generation step not reached or failed.")

    # Optional helper methods can be defined here if needed
    # async def _execute_step(self, step, context, response): ...

    # Optional: Define helper methods for each step type
    # async def _execute_search_code_step(self, step, context, response):
    #     pass
    # async def _execute_analyze_code_step(self, step, context, response):
    #     pass
    # ... etc. 