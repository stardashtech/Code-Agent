import logging
import os
import shutil
import json
import time # Add time import for unique branch names
from typing import TYPE_CHECKING, Any, Dict, List, Optional

# Import config
from config import settings

# Define logger early for use in placeholder
logger = logging.getLogger(__name__) # Define logger at module level

# Import the actual UI confirmation function
try:
    from ui.cli_prompter import ui_confirm
    logger.info("Successfully imported ui_confirm from ui.cli_prompter.")
except ImportError:
    logger.error("Failed to import ui_confirm from ui.cli_prompter. User confirmation step will fail!")
    # Define a dummy function that always denies to prevent accidental confirmation
    # in case of import errors, which is safer than auto-confirming.
    def ui_confirm(prompt: str) -> bool:
        logger.error(f"Cannot prompt user (import failed): {prompt}")
        return False

# Import new step constants
from app.agents.planner import (
    STEP_SEARCH_PKG_MANAGER, STEP_FETCH_DOCS_URL, 
    STEP_SCRAPE_DOCS, STEP_EXTRACT_LLM, STEP_CHECK_VULNS,
    STEP_SEARCH_CODE_VECTOR, STEP_WEB_SEARCH, STEP_GITHUB_SEARCH,
    STEP_STACKOVERFLOW_SEARCH, STEP_ANALYZE_CODE, STEP_GENERATE_FIX,
    STEP_APPLY_FIX, STEP_VALIDATE_CODE
    # Import others if needed
)

# Import necessary utilities and services
from utils import git_utils # Import the git utils
# from .validation_service import ValidationService # Incorrect relative import
# Assuming ValidationService is in the top-level 'services' directory
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))) # Add workspace root to path
from services.validation_service import ValidationService 

# Import client types for type hinting (optional but good practice)
from clients.github_client import GitHubApiClient
from clients.pypi_client import PyPiClient
from clients.npm_client import NpmClient
from clients.go_proxy_client import GoProxyClient
from clients.nuget_client import NuGetClient
from utils.doc_scraper import DocumentationScraper
from tools.llm_info_extractor import LlmInfoExtractor
from interfaces.api_client import ExternalApiClient # Base class

# Use TYPE_CHECKING to avoid circular import issues
if TYPE_CHECKING:
    from .code_agent import CodeAgent
    from .sandbox_runner import SandboxExecutionResult
    # Need the provider type for hinting
    from app.tools.github_search import GitHubSearchProvider

class PlanExecutor:
    """Executes the steps defined in a plan generated by the Planner."""

    def __init__(self, agent: 'CodeAgent'):
        """Initializes the PlanExecutor."""
        self.agent = agent
        # Store references to providers/tools using getattr for safety
        self._github_search_provider: Optional[GitHubSearchProvider] = getattr(agent, 'github_search_provider', None)
        self._pypi_client: Optional[PyPiClient] = getattr(agent, 'pypi_client', None)
        self._npm_client: Optional[NpmClient] = getattr(agent, 'npm_client', None)
        self._go_proxy_client: Optional[GoProxyClient] = getattr(agent, 'go_proxy_client', None)
        self._nuget_client: Optional[NuGetClient] = getattr(agent, 'nuget_client', None)
        self._doc_scraper: Optional[DocumentationScraper] = getattr(agent, 'doc_scraper', None)
        self._llm_extractor: Optional[LlmInfoExtractor] = getattr(agent, 'llm_info_extractor', None)
        self._vector_store_manager = getattr(agent, 'vector_store_manager', None)
        self._llm_provider = getattr(agent, 'provider', None) # LLM Provider is crucial
        self.workspace_root = getattr(agent, 'workspace_root', os.getcwd()) # Default to current dir
        self.validation_service: Optional[ValidationService] = getattr(agent, 'validation_service', None)

        if not self._llm_provider:
             raise ValueError("PlanExecutor requires a valid LLM Provider in the agent.")
        if not self._vector_store_manager:
             logger.warning("PlanExecutor initialized without a Vector Store Manager. Code search capabilities might be limited.")

    def _get_package_client(self, manager_type: str) -> Optional[ExternalApiClient]:
        """Helper to get the correct package manager client based on type."""
        if manager_type == 'pypi':
            return self._pypi_client
        elif manager_type == 'npm':
            return self._npm_client
        elif manager_type == 'go':
            return self._go_proxy_client
        elif manager_type == 'nuget':
            return self._nuget_client
        else:
            logger.warning(f"Unsupported package manager type specified: {manager_type}")
            return None
            
    def _get_source_client(self, source_type: str) -> Optional[Any]: # Changed hint to Any
         """Helper to get client/provider based on source type."""
         client = self._get_package_client(source_type)
         if client:
             return client
         elif source_type == 'github':
             # Return the provider itself, as it has the search method
             return self._github_search_provider
         else:
              logger.warning(f"Unsupported source type specified: {source_type}")
              return None

    async def execute_plan(
        self,
        plan: List[Dict[str, Any]],
        execution_context: Dict[str, Any],
        response_data: Dict[str, Any]
    ) -> None:
        """Executes the plan steps sequentially, updating context and response data."""
        logger.info(f"Starting plan execution with {len(plan)} steps.")
        query = execution_context["query"] # Get query from context

        for step_index, step_details in enumerate(plan): # Use step_details consistently
            step_name = step_details.get("step")
            logger.info(f"Executing step {step_index + 1}/{len(plan)}: {step_name}")

            try:
                # === Existing Core Steps (Refactored slightly for clarity) ===
                if step_name == STEP_SEARCH_CODE_VECTOR:
                    search_query = step_details.get('query', query) # Use step_details
                    use_keywords = step_details.get('use_keywords', True) # Use step_details
                    if use_keywords and execution_context.get('keywords'):
                         search_query += f" {' '.join(execution_context['keywords'])}"
                    logger.info(f"Performing vector search with query: '{search_query}'")
                    code_filter = step_details.get('filter', {"type": "code_master"}) # Use step_details
                    snippets = []
                    if self._vector_store_manager:
                        snippets = await self._vector_store_manager.search_code(search_query, filter_dict=code_filter)
                    else:
                        logger.warning("Vector store manager not available.")
                    execution_context["code_snippets"] = snippets
                    response_data["results"]["code_snippets"] = snippets
                    logger.info(f"Found {len(snippets)} snippets from vector store.")

                # === External Search Steps (Refactored for consistency) ===
                elif step_name == STEP_WEB_SEARCH:
                    web_query = step_details.get('query', query) # Use step_details
                    max_results = step_details.get('max_results', 5) # Use step_details
                    logger.info(f"Performing web search: '{web_query}'")
                    results = []
                    provider = self.agent.web_search_provider # Assuming agent has this
                    if provider and provider.client:
                         try:
                              results = await provider.search(web_query, max_results=max_results)
                              logger.info(f"Web search completed via {provider.__class__.__name__}. Found {len(results)} results.")
                         except Exception as e:
                              logger.error(f"Error during web search: {e}", exc_info=True)
                              results = [{"title": "Error", "content": f"Web search failed: {e}"}]
                    else:
                        logger.warning("Web search provider not configured.")
                        results = [{"title": "Skipped", "content": "Web search provider not configured."}]
                    execution_context["web_search_results"] = results
                    response_data["results"]["web_search_results"] = results

                elif step_name == STEP_GITHUB_SEARCH:
                    gh_query = step_details.get('query', query) # Use step_details
                    language = step_details.get('language') # Use step_details
                    logger.info(f"Performing GitHub search: '{gh_query}' (Lang: {language or 'any'})")
                    results = []
                    # Use the search provider directly
                    if self._github_search_provider:
                         try:
                              # Call the search method on the provider
                              results = await self._github_search_provider.search(gh_query, language=language)
                              logger.info(f"GitHub search completed. Found {len(results)} results.")
                         except Exception as e:
                              logger.error(f"Error during GitHub search: {e}", exc_info=True)
                              results = [{"error": f"GitHub search failed: {e}"}]
                    else:
                         logger.warning("GitHub search provider not available.")
                         results = [{"error": "GitHub search provider not initialized."}]
                    execution_context["github_results"] = results
                    response_data["results"]["github_search_results"] = results

                # === New Package/Docs/Vulns Steps ===
                elif step_name == STEP_SEARCH_PKG_MANAGER:
                     manager_type = step_details.get('manager_type') # Use step_details
                     pkg_query = step_details.get('query', query) # Use step_details
                     logger.info(f"Searching package manager ({manager_type or 'unknown'}) for: '{pkg_query}'")
                     client = self._get_package_client(manager_type)
                     results = []
                     if client:
                         try:
                             # Assuming search_repositories for package managers also searches packages
                             results = client.search_repositories(pkg_query)
                             logger.info(f"Package manager search completed ({manager_type}). Found {len(results)} results.")
                         except Exception as e:
                             logger.error(f"Error during {manager_type} package search: {e}", exc_info=True)
                             results = [{"error": f"Package search failed ({manager_type}): {e}"}]
                     else:
                         results = [{"error": f"Package manager client for {manager_type} not available."}]
                     # Store under a generic key or manager-specific key?
                     context_key = f"{manager_type}_search_results"
                     execution_context[context_key] = results
                     response_data["results"][context_key] = results
                     
                elif step_name == STEP_FETCH_DOCS_URL:
                     source_type = step_details.get('source_type') # Use step_details
                     package_name = step_details.get('package_name') # Name or repo identifier # Use step_details
                     if not source_type or not package_name:
                         logger.warning(f"Skipping {step_name}: Missing 'source_type' or 'package_name' in plan step.")
                         execution_context["documentation_url"] = None
                     else:
                         logger.info(f"Fetching documentation URL for '{package_name}' from source: {source_type}")
                         source_handler = self._get_source_client(source_type) # Can be provider or client
                         doc_url = None
                         if source_handler:
                             try:
                                 # Version might come from context if available (e.g., from pkg search)
                                 version = execution_context.get(f"{source_type}_latest_version") 
                                 # Check if the handler has the method before calling
                                 if hasattr(source_handler, 'fetch_documentation_url'):
                                     doc_url = source_handler.fetch_documentation_url(package_name, version=version)
                                     logger.info(f"Found documentation URL: {doc_url}")
                                 else:
                                     logger.warning(f"Source handler for {source_type} does not support fetching documentation URL.")
                             except Exception as e:
                                 logger.error(f"Error fetching documentation URL for {package_name} ({source_type}): {e}", exc_info=True)
                         else:
                              logger.warning(f"Client/Provider for source type {source_type} not available.")
                         execution_context["documentation_url"] = doc_url
                         # Optionally add to response_data if needed directly
                         # response_data["results"]["documentation_url"] = doc_url
                         
                elif step_name == STEP_SCRAPE_DOCS:
                     # Get URL from context (likely set by previous step)
                     url_to_scrape = step_details.get('url') or execution_context.get("documentation_url") # Use step_details
                     if not url_to_scrape:
                         logger.warning(f"Skipping {step_name}: No URL provided in step or context.")
                         execution_context["scraped_content"] = None
                     else:
                         logger.info(f"Scraping documentation content from: {url_to_scrape}")
                         content = None
                         if self._doc_scraper:
                             try:
                                 content = self._doc_scraper.fetch_content(url_to_scrape)
                                 logger.info(f"Scraping completed. Content length: {len(content) if content else 0}")
                             except Exception as e:
                                 logger.error(f"Error during documentation scraping: {e}", exc_info=True)
                         else:
                             logger.warning("Documentation scraper not available.")
                         execution_context["scraped_content"] = content
                         # Only store summary in response_data to avoid large payloads?
                         response_data["results"]["scraped_content_summary"] = (content[:500] + '...') if content and len(content) > 500 else content
                         
                elif step_name == STEP_EXTRACT_LLM:
                     prompt_key = step_details.get('prompt_key') # Use step_details
                     # Get content preferentially from 'scraped_content', fallback to snippets?
                     content_to_analyze = execution_context.get("scraped_content")
                     
                     if not prompt_key:
                         logger.warning(f"Skipping {step_name}: Missing 'prompt_key' in plan step.")
                         execution_context["llm_extracted_info"] = None
                     elif not content_to_analyze:
                         logger.warning(f"Skipping {step_name}: No content found in context (e.g., 'scraped_content') to analyze.")
                         execution_context["llm_extracted_info"] = None
                     elif not self._llm_extractor:
                         logger.warning(f"Skipping {step_name}: LLM Info Extractor not available.")
                         execution_context["llm_extracted_info"] = None
                     else:
                         logger.info(f"Extracting information using LLM with prompt key: '{prompt_key}'")
                         # Pass relevant context for prompt formatting
                         llm_context = step_details.get('context', {}) # Allow plan to provide extra context # Use step_details
                         llm_context.update({
                             'language': execution_context.get('language'), # Infer language if possible
                             'package_name': execution_context.get('package_name') # Infer package name
                             # Add other relevant context fields
                         })
                         extracted_info = None
                         try:
                             extracted_info = self._llm_extractor.extract(prompt_key, content_to_analyze, context=llm_context)
                             logger.info(f"LLM extraction completed. Result type: {type(extracted_info)}")
                         except Exception as e:
                              logger.error(f"Error during LLM information extraction: {e}", exc_info=True)
                         execution_context["llm_extracted_info"] = extracted_info
                         # Store potentially structured info in response
                         response_data["results"][f"extracted_{prompt_key}"] = extracted_info 
                         
                elif step_name == STEP_CHECK_VULNS:
                     source_type = step_details.get('source_type') # e.g., pypi, nuget # Use step_details
                     package_name = step_details.get('package_name') # Use step_details
                     version = step_details.get('version') # Needs version context! # Use step_details
                     
                     if not all([source_type, package_name, version]):
                         logger.warning(f"Skipping {step_name}: Missing 'source_type', 'package_name', or 'version' in plan step or context.")
                         execution_context["vulnerabilities"] = []
                     else:
                         logger.info(f"Checking vulnerabilities for {package_name} v{version} (Source: {source_type})")
                         source_handler = self._get_source_client(source_type)
                         vulns = []
                         if source_handler:
                             try:
                                 # Check if the handler has the method before calling
                                 if hasattr(source_handler, 'check_vulnerabilities'):
                                     vulns = source_handler.check_vulnerabilities(package_name, version)
                                     logger.info(f"Vulnerability check completed. Found {len(vulns)} potential vulnerabilities.")
                                 else:
                                     logger.warning(f"Source handler for {source_type} does not support vulnerability checks.")
                             except Exception as e:
                                 logger.error(f"Error during vulnerability check for {package_name} ({source_type}): {e}", exc_info=True)
                         else:
                              logger.warning(f"Client/Provider for source type {source_type} not available for vulnerability check.")
                         execution_context["vulnerabilities"] = vulns
                         response_data["results"]["vulnerabilities"] = vulns

                # === Analysis and Fix Steps (Ensure context usage) ===
                elif step_name == STEP_ANALYZE_CODE:
                     # Gather all relevant context gathered so far
                     analysis_input_parts = []
                     if execution_context.get("code_snippets"):
                          combined_code = "\n\n---\n\n".join([
                                f"File: {snippet['file_path']}\n```\n{snippet['code']}\n```"
                                for snippet in execution_context["code_snippets"] if snippet.get('code')
                            ])
                          if combined_code.strip():
                               analysis_input_parts.append("--- Local Code Snippets ---\n" + combined_code)
                               
                     # Include results from various searches and extractions
                     for key, title in [
                         ("web_search_results", "Web Search Results"),
                         ("github_results", "GitHub Search Results"),
                         # ("stackoverflow_results", "Stack Overflow Results"), # If enabled
                         ("pypi_search_results", "PyPI Search Results"), 
                         ("npm_search_results", "npm Search Results"),
                         ("go_search_results", "Go Search Results"), # Assuming these keys are used
                         ("nuget_search_results", "NuGet Search Results"),
                         ("scraped_content_summary", "Scraped Documentation Summary"),
                         ("llm_extracted_info", "LLM Extracted Info"), # Generic key
                         ("vulnerabilities", "Vulnerabilities Found")
                     ]:
                         if execution_context.get(key):
                              # Simple string representation for now
                              info_str = f"\n\n--- {title} ---\n"
                              if isinstance(execution_context[key], list):
                                   info_str += json.dumps(execution_context[key][:3], indent=2) # Show first few items
                                   if len(execution_context[key]) > 3: info_str += "\n... (more results exist)"
                              elif isinstance(execution_context[key], dict):
                                   info_str += json.dumps(execution_context[key], indent=2)
                              else:
                                   info_str += str(execution_context[key])[:1000] # Limit length
                              analysis_input_parts.append(info_str)
                              logger.info(f"Including {title} in analysis context.")
                              
                     # Include specific LLM extractions by key if available
                     for resp_key in response_data["results"]:
                         if resp_key.startswith("extracted_"):
                             prompt_key_used = resp_key[len("extracted_"):]
                             info_str = f"\n\n--- LLM Extracted Info ({prompt_key_used}) ---\n"
                             info_str += json.dumps(response_data["results"][resp_key], indent=2) if isinstance(response_data["results"][resp_key], (dict, list)) else str(response_data["results"][resp_key])
                             analysis_input_parts.append(info_str)
                             logger.info(f"Including LLM extraction result '{prompt_key_used}' in analysis context.")
                             
                     # Add Decomposed Queries
                     if execution_context.get("decomposed_queries"):
                         unique_sub_queries = list(set(execution_context["decomposed_queries"]))
                         if len(unique_sub_queries) > 1 or (len(unique_sub_queries) == 1 and unique_sub_queries[0] != execution_context["query"]):
                                 decomp_info = "\n\n--- Original Query Decomposition ---"
                                 for i, sub_query in enumerate(execution_context["decomposed_queries"]):
                                         decomp_info += f"\n{i+1}. {sub_query}"
                                 analysis_input_parts.append(decomp_info)
                                 logger.info("Including decomposed queries in analysis context.")

                     if not analysis_input_parts:
                         logger.warning("Skipping Analyze Code step: No context available.")
                         execution_context["analysis"] = "Analysis skipped: No relevant information gathered."
                     elif not self.agent.analyze_code: # Check if method exists on agent
                          logger.error("Analyze code method not found on agent.")
                          execution_context["analysis"] = "Error: Analysis capability not available."
                     else:
                         final_analysis_context = "\n".join(analysis_input_parts)
                         # Pass original query for context
                         original_query = execution_context.get("query", "")
                         execution_context["analysis"] = await self.agent.analyze_code(
                                 code=final_analysis_context, # Pass combined context as 'code' for now
                                 original_query=original_query
                         )
                         logger.info("Code analysis completed using gathered context.")
                     response_data["results"]["analysis_summary"] = execution_context.get("analysis", "Analysis failed or skipped.")

                elif step_name == STEP_GENERATE_FIX:
                    # Ensure analysis is used if available
                    analysis_context = execution_context.get("analysis") or "No prior analysis available."
                    code_snippets = execution_context.get("code_snippets", [])
                    
                    if not code_snippets and not analysis_context:
                            logger.warning("Skipping Generate Fix: No code snippets or analysis.")
                            code_fix = self.agent._generate_error_response("Fix generation skipped: No input.") if hasattr(self.agent, '_generate_error_response') else {"status":"error", "explanation":"Fix generation skipped: No input."}
                    elif not self.agent._generate_code_fix: # Check if method exists
                         logger.error("Generate code fix method not found on agent.")
                         code_fix = {"status":"error", "explanation":"Fix generation capability not available."}
                    else:
                        code_fix = await self.agent._generate_code_fix(
                            execution_context.get("query", ""),
                            code_snippets,
                            analysis_context
                        )
                        logger.info("Code fix generation process completed.")
                        
                    response_data["results"]["fix_details"] = code_fix
                    response_data["status"] = code_fix.get("status", "error") # Default to error if status missing
                    response_data["message"] = code_fix.get("explanation", "Fix generation finished.")

                elif step_name == STEP_APPLY_FIX:
                    logger.info(f"Executing step: {step_name}")
                    # Attempt to get fix details from the context (usually set by GENERATE_FIX)
                    fix_details = execution_context.get("fix_details") or response_data["results"].get("fix_details")

                    if not fix_details or not isinstance(fix_details, dict):
                         error_message = f"Skipping {step_name}: No valid fix details found in context."
                         logger.warning(error_message)
                         execution_context[f"{step_name}_error"] = error_message
                         execution_context[f"{step_name}_status"] = "skipped"
                         continue

                    target_file = fix_details.get("file_path")
                    fixed_code = fix_details.get("fixed_code")
                    syntax_check_status = fix_details.get("syntax_check", {}).get("status", "unknown")

                    # --- Pre-checks --- 
                    if not target_file or fixed_code is None:
                        error_message = f"Skipping {step_name}: 'file_path' or 'fixed_code' missing in fix details."
                        logger.warning(error_message)
                        execution_context[f"{step_name}_error"] = error_message
                        execution_context[f"{step_name}_status"] = "skipped_missing_info"
                        continue
                        
                    if syntax_check_status == "failed":
                        error_message = f"Skipping {step_name}: Generated code failed syntax check. Details: {fix_details.get('syntax_check', {}).get('error')}"
                                        logger.error(error_message)
                        execution_context[f"{step_name}_error"] = error_message
                        execution_context[f"{step_name}_status"] = "skipped_syntax_error"
                        continue
                         
                    # Normalize file path
                    if not isinstance(target_file, str):
                         logger.warning(f"Invalid target_file type in fix_details: {type(target_file)}. Skipping.")
                         execution_context[f"{step_name}_status"] = "skipped_invalid_path"
                         continue
                    target_file = target_file.strip()
                    if not target_file:
                         logger.warning(f"Empty target_file specified in fix_details. Skipping.")
                         execution_context[f"{step_name}_status"] = "skipped_empty_path"
                         continue
                         
                    # Ensure path is relative to workspace root and prevent directory traversal
                    normalized_path = os.path.normpath(os.path.join(self.workspace_root, target_file))
                    if not normalized_path.startswith(self.workspace_root):
                         error_message = f"Error in {step_name}: Attempted path traversal in target file: {target_file}"
                         logger.error(error_message)
                         execution_context[f"{step_name}_error"] = error_message
                         execution_context[f"{step_name}_status"] = "failed_path_traversal"
                         break # Stop execution for security

                    full_target_path = normalized_path
                    relative_target_file = os.path.relpath(full_target_path, self.workspace_root)

                    logger.debug(f"Target file path (absolute): {full_target_path}")
                    logger.debug(f"Target file path (relative): {relative_target_file}")
                    logger.debug(f"Code to write (syntax check: {syntax_check_status}):\n```\n{fixed_code[:200]}...\n```") # Log snippet

                    # --- Git Rollback Implementation ---
                    repo_path = self.workspace_root
                    use_git = git_utils.GITPYTHON_INSTALLED and git_utils._is_git_repo(repo_path) # Check if it's a repo
                    original_branch = None
                    temp_branch_name = None
                    git_error = None
                    apply_success = False

                    if not use_git:
                        logger.warning("GitPython not installed or not a Git repo. Applying changes directly without Git workflow.")
                        # Proceed with direct file writing without Git protection
                        try:
                            os.makedirs(os.path.dirname(full_target_path), exist_ok=True)
                            with open(full_target_path, 'w', encoding='utf-8') as f:
                                f.write(fixed_code)
                            logger.info(f"Successfully wrote changes to {relative_target_file} (No Git).")
                            execution_context[f"{step_name}_status"] = "completed_no_git"
                            execution_context["last_applied_file"] = relative_target_file
                        except Exception as e:
                            error_message = f"Error writing file {relative_target_file} (No Git): {e}"
                            logger.error(error_message, exc_info=True)
                            execution_context[f"{step_name}_error"] = error_message
                            execution_context[f"{step_name}_status"] = "failed"
                        continue # Move to next step

                    # --- Git Workflow Starts Here ---
                    logger.info("Using Git workflow for safe application of changes.")
                    try:
                        # 1. Check repo status
                        original_branch = git_utils.get_current_branch(repo_path)
                        if original_branch is None:
                            raise Exception("Could not determine current branch (detached HEAD?).")

                        if git_utils.has_uncommitted_changes(repo_path):
                             raise Exception("Repository has uncommitted changes. Please commit or stash them before applying fixes.")

                        logger.info(f"Original branch: {original_branch}")
                        # Store original branch for potential validation step
                        execution_context["original_branch_before_apply"] = original_branch

                        # 2. Create temporary branch
                        timestamp = time.strftime("%Y%m%d%H%M%S")
                        temp_branch_name = f"code-agent-fix-{relative_target_file.replace('/ ', '-')}-{timestamp}"[:50] # Keep branch name reasonable
                        if not git_utils.create_branch(temp_branch_name, start_point=original_branch, repo_path=repo_path):
                             raise Exception(f"Failed to create temporary branch: {temp_branch_name}")
                        logger.info(f"Created temporary branch: {temp_branch_name}")

                        # 3. Checkout temporary branch
                        if not git_utils.checkout_branch(temp_branch_name, repo_path=repo_path):
                             raise Exception(f"Failed to checkout temporary branch: {temp_branch_name}")
                        logger.info(f"Checked out temporary branch: {temp_branch_name}")

                        # 4. Apply file changes
                        try:
                            os.makedirs(os.path.dirname(full_target_path), exist_ok=True)
                            with open(full_target_path, 'w', encoding='utf-8') as f:
                                f.write(fixed_code)
                            logger.info(f"Successfully wrote changes to {relative_target_file} on branch {temp_branch_name}.")
                            apply_success = True # Mark apply as successful before commit
                        except Exception as e:
                             raise Exception(f"Error writing file {relative_target_file} on branch {temp_branch_name}: {e}")

                        # 5. Add file to index
                        if not git_utils.add_files([relative_target_file], repo_path=repo_path):
                             raise Exception(f"Failed to add file {relative_target_file} to index on branch {temp_branch_name}.")
                        logger.info(f"Added {relative_target_file} to index.")

                        # 6. Commit changes
                        commit_message = f"Code-Agent: Applied fix to {relative_target_file}\n\n{fix_details.get('explanation', '')[:100]}" # Include brief explanation
                        commit_successful = git_utils.commit_changes(commit_message, repo_path=repo_path)
                        
                        if not commit_successful:
                             # Check if it failed because there were no changes staged (e.g., identical file content)
                             if not git_utils._get_repo(repo_path).is_dirty(index=True, working_tree=False):
                                 logger.warning(f"No actual changes detected in {relative_target_file} after writing. Skipping commit.")
                                 commit_successful = True # Treat as success if no changes
                             else:
                                 raise Exception(f"Failed to commit changes on branch {temp_branch_name}.")
                        else:
                             logger.info(f"Committed changes with message: '{commit_message.splitlines()[0]}'")

                        # 7. Set context for validation step
                        execution_context["last_applied_file"] = relative_target_file
                        execution_context["branch_for_validation"] = temp_branch_name # Pass temp branch name
                        execution_context[f"{step_name}_status"] = "completed_pending_validation"
                        logger.info(f"File {relative_target_file} applied and committed on {temp_branch_name}. Ready for validation step.")

                    except Exception as e:
                        git_error = f"Error during Git workflow ({step_name}): {e}"
                        logger.error(git_error, exc_info=True)
                        execution_context[f"{step_name}_error"] = git_error
                        execution_context[f"{step_name}_status"] = "failed"
                        # Cleanup happens in finally

                    finally:
                        # --- Cleanup if APPLY_FIX failed *during its own execution* --- 
                        if original_branch and temp_branch_name and (git_error or not apply_success):
                            current_on_exit = git_utils.get_current_branch(repo_path)
                            logger.info(f"Entering finally block for {step_name} after error. Current: {current_on_exit}, Original: {original_branch}, Temp: {temp_branch_name}")
                            # Ensure we are back on the original branch
                            if current_on_exit != original_branch:
                                logger.warning(f"Attempting checkout back to original branch '{original_branch}'...")
                                if not git_utils.checkout_branch(original_branch, repo_path=repo_path):
                                    logger.error(f"CRITICAL: Failed to checkout original branch '{original_branch}' during error cleanup!")
                                else:
                                    logger.info(f"Successfully checked out original branch '{original_branch}'.")
                            # Delete the temporary branch if it exists
                                logger.warning(f"Rolling back changes due to error in {step_name}. Deleting temporary branch {temp_branch_name}.")
                            if git_utils.delete_branch(temp_branch_name, force=True, repo_path=repo_path):
                                logger.info(f"Successfully deleted temporary branch {temp_branch_name}.")
                                    execution_context[f"{step_name}_status"] = "rolled_back_apply_error"
                            else:
                                logger.error(f"Failed to delete temporary branch {temp_branch_name} during rollback.")
                            # Clean up context specific to this failed attempt
                            if "branch_for_validation" in execution_context: del execution_context["branch_for_validation"]
                            if "original_branch_before_apply" in execution_context: del execution_context["original_branch_before_apply"]
                        elif not use_git: # No Git cleanup needed if not using Git
                             pass 
                        elif execution_context.get(f"{step_name}_status") != "completed_pending_validation":
                             logger.debug(f"Skipping Git cleanup in {step_name} finally (no error or status is {execution_context.get(f'{step_name}_status')}).")
                            # If completed_pending_validation, responsibility shifts to VALIDATE step

                        continue # Explicitly continue loop

                elif step_name == STEP_VALIDATE_CODE:
                    logger.info(f"Executing step: {step_name}")
                    # Check if validation should run on a specific branch from a previous APPLY_FIX step
                    validation_branch = execution_context.get("branch_for_validation")
                    original_branch_from_apply = execution_context.get("original_branch_before_apply") # Get the branch stored by APPLY_FIX
                    repo_path = self.workspace_root
                    current_branch_before_validation = git_utils.get_current_branch(repo_path) # Branch *before* potential checkout
                    branch_to_return_to_after_validation = current_branch_before_validation # Default return branch
                    needs_checkout_back = False
                    validation_run = False # Flag to track if validation commands actually ran

                    # Check if validation service is available
                    if not self.validation_service:
                         logger.warning("Validation service not available. Skipping validation step.")
                         execution_context[f"{step_name}_status"] = "skipped"
                         # If skipping validation, but there was a temp branch, we need to decide what to do.
                         # Defaulting to rollback might be safest.
                         if validation_branch and original_branch_from_apply:
                              logger.warning(f"Validation skipped, rolling back changes from branch {validation_branch}")
                              # Ensure we are on the original branch before deleting temp branch
                              if current_branch_before_validation != original_branch_from_apply:
                                   if not git_utils.checkout_branch(original_branch_from_apply, repo_path=repo_path):
                                        logger.error(f"CRITICAL: Failed checkout to {original_branch_from_apply} before rollback (validation skipped).")
                                        # Cannot safely delete branch
                                   else:
                                        if git_utils.delete_branch(validation_branch, force=True, repo_path=repo_path):
                                             logger.info(f"Successfully deleted temporary branch {validation_branch} (validation skipped).")
                                             execution_context[f"{STEP_APPLY_FIX}_status"] = "rolled_back_validation_skipped"
                                        else:
                                             logger.error(f"Failed to delete temp branch {validation_branch} after skipping validation.")
                              else: # Already on original branch
                                   if git_utils.delete_branch(validation_branch, force=True, repo_path=repo_path):
                                        logger.info(f"Successfully deleted temporary branch {validation_branch} (validation skipped).")
                                        execution_context[f"{STEP_APPLY_FIX}_status"] = "rolled_back_validation_skipped"
                                   else:
                                        logger.error(f"Failed to delete temp branch {validation_branch} after skipping validation.")
                         continue # Skip to next step


                    # --- Git Branch Handling for Validation ---
                    if validation_branch:
                         if current_branch_before_validation != validation_branch:
                              logger.warning(f"Validation step needs branch '{validation_branch}', but currently on '{current_branch_before_validation}'. Checking out...")
                              if not original_branch_from_apply:
                                   logger.error("CRITICAL: Cannot perform validation checkout - original branch before apply step is unknown!")
                                   execution_context[f"{step_name}_error"] = "Cannot checkout validation branch: unknown original branch."
                                   execution_context[f"{step_name}_status"] = "failed"
                                   # Attempt to delete the temp branch as we can't proceed
                                   if git_utils.delete_branch(validation_branch, force=True, repo_path=repo_path):
                                       logger.info(f"Deleted unusable temporary branch {validation_branch}.")
                                   else:
                                       logger.error(f"Failed to delete unusable temporary branch {validation_branch}.")
                                   continue # Skip validation

                              branch_to_return_to_after_validation = original_branch_from_apply # Set the correct return branch
                              if git_utils.checkout_branch(validation_branch, repo_path=repo_path):
                                   logger.info(f"Checked out branch '{validation_branch}' for validation.")
                                   needs_checkout_back = True # Remember to checkout back
                              else:
                                   error_message = f"Failed to checkout branch '{validation_branch}' for validation. Skipping validation and rolling back."
                                   logger.error(error_message)
                                   execution_context[f"{step_name}_error"] = error_message
                                   execution_context[f"{step_name}_status"] = "failed"
                                   # Rollback: Checkout original and delete temp branch
                                   if git_utils.checkout_branch(original_branch_from_apply, repo_path=repo_path):
                                        if git_utils.delete_branch(validation_branch, force=True, repo_path=repo_path):
                                             logger.info(f"Successfully rolled back by deleting branch {validation_branch}.")
                                             execution_context[f"{STEP_APPLY_FIX}_status"] = "rolled_back_checkout_failed"
                                        else:
                                             logger.error(f"Failed to delete temp branch {validation_branch} during rollback.")
                                   else:
                                        logger.error(f"CRITICAL: Failed checkout back to {original_branch_from_apply} during rollback.")
                                   continue # Skip validation step

                         else: # Already on the validation branch
                              logger.info(f"Already on the correct branch '{validation_branch}' for validation.")
                              if not original_branch_from_apply:
                                   logger.error("CRITICAL: On validation branch, but original branch context is missing!")
                                   # Cannot safely merge or rollback later. What to do?
                                   # Maybe try to infer original from config? Risky.
                                   # For now, log error and potentially skip merge/delete later.
                                   execution_context[f"{step_name}_error"] = "Missing original branch context while on validation branch."
                              else:
                                  branch_to_return_to_after_validation = original_branch_from_apply


                    # --- Run Validation Commands ---
                    try:
                        commands = step_details.get("commands", []) # Use step_details
                        if not commands:
                             logger.warning(f"No validation commands provided for {step_name}.")
                             execution_context[f"{step_name}_status"] = "skipped"
                        else:
                             logger.info(f"Running validation commands on branch '{git_utils.get_current_branch(repo_path)}'...")
                             success = self.validation_service.run_validation_commands(commands)
                             validation_run = True # Mark validation as run
                             if success:
                                  logger.info("Validation commands completed successfully.")
                                  execution_context[f"{step_name}_status"] = "completed"
                             else:
                                  error_message = "Validation commands failed."
                                  logger.error(error_message)
                                  # Log stderr from the validation command
                                  stderr_output = self.validation_service.get_last_result().get('stderr', '') if hasattr(self.validation_service, 'get_last_result') and self.validation_service.get_last_result() else ''
                                  full_error_message = f"{error_message}\nValidation STDERR:\n{stderr_output}"
                                  execution_context[f"{step_name}_error"] = full_error_message
                                  execution_context[f"{step_name}_status"] = "failed"

                    except Exception as e:
                        error_message = f"Error during validation execution ({step_name}): {e}"
                        logger.error(error_message, exc_info=True)
                        execution_context[f"{step_name}_error"] = error_message
                        execution_context[f"{step_name}_status"] = "failed"
                        validation_run = True # It was attempted

                    finally:
                        # --- Post-Validation: Merge or Rollback & Cleanup ---
                        validation_status = execution_context.get(f"{step_name}_status")
                        validation_passed = validation_run and validation_status == "completed"
                        temp_branch_to_finalize = execution_context.get("branch_for_validation")

                        logger.info(f"Entering finally block for {step_name}. Validation run: {validation_run}, Status: {validation_status}, Passed: {validation_passed}, Temp branch: {temp_branch_to_finalize}, Branch to return to: {branch_to_return_to_after_validation}")

                        # --- Merge/Rollback logic (only if validation followed an APPLY_FIX) ---
                        if temp_branch_to_finalize:
                            if not branch_to_return_to_after_validation: # Should be original_branch_from_apply
                                logger.error(f"CRITICAL: Cannot finalize Git workflow for '{temp_branch_to_finalize}' - target branch to return to is unknown!")
                                # Leave the temp branch? Maybe checkout default branch if possible?
                            else:
                                 current_branch_after_validation = git_utils.get_current_branch(repo_path)
                                 # Ensure we are on the target branch before merge/delete
                                 if current_branch_after_validation != branch_to_return_to_after_validation:
                                      logger.info(f"Checking out target branch '{branch_to_return_to_after_validation}' before finalizing '{temp_branch_to_finalize}'.")
                                      if not git_utils.checkout_branch(branch_to_return_to_after_validation, repo_path=repo_path):
                                           logger.error(f"CRITICAL: Failed to checkout target branch '{branch_to_return_to_after_validation}' before finalizing Git workflow! Cannot merge/delete '{temp_branch_to_finalize}'.")
                                           # Skip merge/delete as we are in an unknown state
                                      else:
                                           current_branch_after_validation = branch_to_return_to_after_validation # Update current branch tracking

                                 # Now, perform merge or delete based on validation outcome
                                 if current_branch_after_validation == branch_to_return_to_after_validation:
                                     user_confirmed_merge = True # Default to true, check risk below
                                     if validation_passed:
                                        # --- TASK-004.7: User Confirmation Check ---
                                        risk_assessment = execution_context.get('risk_assessment_result')
                                        assessed_risk_level_str = risk_assessment.get('risk_level', 'UNKNOWN') if risk_assessment else 'UNKNOWN'
                                        threshold_str = settings.RISK_CONFIRMATION_THRESHOLD.upper()
                                        
                                        risk_map = {'LOW': 0, 'MEDIUM': 1, 'HIGH': 2, 'CRITICAL': 3, 'UNKNOWN': -1}
                                        assessed_risk_level = risk_map.get(assessed_risk_level_str.upper(), -1)
                                        threshold_level = risk_map.get(threshold_str, risk_map['MEDIUM']) # Default threshold MEDIUM

                                        logger.info(f"Assessed risk: {assessed_risk_level_str} ({assessed_risk_level}). Confirmation threshold: {threshold_str} ({threshold_level}).")

                                        if assessed_risk_level >= threshold_level:
                                            logger.warning(f"Risk level '{assessed_risk_level_str}' meets or exceeds threshold '{threshold_str}'. Requesting user confirmation.")
                                            confirmation_prompt = (
                                                f"Proposed changes in branch '{temp_branch_to_finalize}' have been validated. \n"
                                                f"Risk assessed as: {assessed_risk_level_str}. \n"
                                                f"Do you want to merge these changes into '{branch_to_return_to_after_validation}'? (yes/no): "
                                            )
                                            try:
                                                user_confirmed_merge = ui_confirm(confirmation_prompt)
                                            except Exception as ui_e:
                                                logger.error(f"Error during UI confirmation: {ui_e}. Assuming NO confirmation.", exc_info=True)
                                                user_confirmed_merge = False
                                                
                                            if user_confirmed_merge:
                                                 logger.info("User confirmed the merge.")
                                            else:
                                                 logger.warning("User rejected the merge based on risk assessment.")
                                                 # Update APPLY_FIX status to reflect rejection
                                                 execution_context[f"{STEP_APPLY_FIX}_status"] = "rejected_by_user"
                                                 # Skip the merge logic by setting validation_passed effectively to False for merge decision
                                                 validation_passed = False 
                                        else:
                                             logger.info("Risk level below threshold. Proceeding with merge automatically.")
                                        # --- End TASK-004.7 ---

                                        # Proceed with merge only if validation passed AND user confirmed (if needed)
                                        if validation_passed and user_confirmed_merge: 
                                            # Merge the temporary branch
                                            logger.info(f"Validation passed and user confirmed (if required). Merging '{temp_branch_to_finalize}' into '{branch_to_return_to_after_validation}'.")
                                            if git_utils.merge_branch(temp_branch_to_finalize, target_branch=branch_to_return_to_after_validation, repo_path=repo_path):
                                                logger.info("Merge successful.")
                                                execution_context[f"{STEP_APPLY_FIX}_status"] = "completed_and_merged" # Update APPLY step status
                                                # Delete the temporary branch after successful merge
                                                if git_utils.delete_branch(temp_branch_to_finalize, force=False, repo_path=repo_path): # No force needed after merge
                                                    logger.info(f"Deleted temporary branch '{temp_branch_to_finalize}'.")
                                                else:
                                                    logger.warning(f"Failed to delete temporary branch '{temp_branch_to_finalize}' after merge.")
                                            else:
                                                logger.error(f"Failed to merge branch '{temp_branch_to_finalize}' into '{branch_to_return_to_after_validation}'. Manual intervention may be needed.")
                                                execution_context[f"{STEP_APPLY_FIX}_status"] = "merge_failed"
                                                # Keep the temp branch for inspection.

                                     # This 'else' covers: validation failed OR validation passed but user rejected merge
                                     if not validation_passed or not user_confirmed_merge:
                                         # Rollback: Delete the temporary branch
                                         rollback_reason = "Validation failed or skipped" if not validation_passed else "User rejected merge"
                                         logger.warning(f"{rollback_reason}. Rolling back by deleting temporary branch '{temp_branch_to_finalize}'.")
                                         if git_utils.delete_branch(temp_branch_to_finalize, force=True, repo_path=repo_path):
                                             logger.info(f"Successfully deleted temporary branch '{temp_branch_to_finalize}'.")
                                             # Update APPLY_FIX status to reflect rollback after validation phase
                                             execution_context[f"{STEP_APPLY_FIX}_status"] = "rolled_back_post_validation"
                                         else:
                                             logger.error(f"Failed to delete temporary branch '{temp_branch_to_finalize}' during rollback.")
                                             execution_context[f"{STEP_APPLY_FIX}_status"] = "rollback_failed" # Indicate branch delete failed
                                 else:
                                     logger.error(f"Could not ensure checkout to target branch '{branch_to_return_to_after_validation}'. Skipping merge/delete of '{temp_branch_to_finalize}'.")


                            # Clean up context variables related to the Git workflow for this fix
                            if "branch_for_validation" in execution_context: del execution_context["branch_for_validation"]
                            if "original_branch_before_apply" in execution_context: del execution_context["original_branch_before_apply"]

                        # --- Checkout back if validation ran on a different branch (non-APPLY_FIX case) ---
                        elif needs_checkout_back:
                            logger.info(f"Validation finished. Checking back out to '{branch_to_return_to_after_validation}'.")
                            if not git_utils.checkout_branch(branch_to_return_to_after_validation, repo_path=repo_path):
                                 logger.error(f"CRITICAL: Failed to checkout back to '{branch_to_return_to_after_validation}' after validation.")


                    # Continue to the next step in the plan
                    continue # Explicitly continue loop

                elif step_name in ["Assess Clarity", "Extract Keywords", "Decompose Query"]:
                    # These steps are handled before plan execution
                    logger.debug(f"Skipping step '{step_name}' as it was handled in reflection phase.")
                    pass
                
                else:
                        logger.warning(f"Unknown or unsupported plan step encountered: {step_name}")
                        response_data["results"][step_name] = {"status": "skipped", "reason": "Unknown step type"}

            except Exception as e:
                logger.error(f"Error executing plan step '{step_name}': {e}", exc_info=True)
                response_data["status"] = "error"
                response_data["message"] = f"An error occurred during step: {step_name}. See logs for details."
                response_data["results"][step_name] = {"status": "error", "error_message": str(e)}
                # Decide whether to stop execution on error or continue
                # For now, let's stop the plan execution on any step error
                logger.error("Plan execution stopped due to error.")
                break # Stop the loop

        # Final status update if plan completed without breaking
        if response_data.get("status") == "processing":
            response_data["status"] = "completed"
            response_data["message"] = response_data.get("message", "Plan executed successfully.") # Provide a default success message

        logger.info(f"Plan execution finished with status: {response_data.get('status')}")

    # Optional helper methods can be defined here if needed
    # async def _execute_step(self, step, context, response): ...

    # Optional: Define helper methods for each step type
    # async def _execute_search_code_step(self, step, context, response):
    #     pass
    # async def _execute_analyze_code_step(self, step, context, response):
    #     pass
    # ... etc. 

    def _run_step(self, step_details: Dict[str, Any], execution_context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Helper method to run a single step.
        (This function is not used in the current loop structure but kept for potential refactoring)
        """
        step_name = step_details.get("step") # Use step_details
        logger.info(f"Running step: {step_name}")
        # ... (Logic for each step would go here if refactored) ...
        raise NotImplementedError("Refactor needed to use _run_step method.")

    # ... existing code ... 